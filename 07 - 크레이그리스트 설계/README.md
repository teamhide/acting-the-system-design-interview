# 07장. 크레이그리스트 설계

## 7.1 사용자 스토리와 요구사항

크레이그리스트의 주요 사용자 유형은 조회자와 게시자로 구분한다. 게시자는 게시물 작성/삭제/검색하며 게시물에는 다음 다음 정보를 포함해야한다.

- 제목
- 설명 문단 몇개
- 가격, 단일 통화를 가정하고 통화 변환은 무시
- 위치
- 최대 10장의 사진(각 1MB)
- 동영상, 애플리케이션의 후속 버전에서 추가될 수 있음

게시자는 7일마다 게시물을 갱신할 수 있다. 게시물을 갱신할 수 있는 클릭 링크가 포함된 이메일 알림을 받게 된다.

조회자는 다음을 할 수 있어야 한다.

1. 지난 7일 동안 특정 도시에서 작성된 모든 게시물을 보거나 검색한다. 결과 목록을 끝없이 스크롤하여 본다.
2. 결과에 필터를 적용한다.
3. 개별 게시물을 클릭해 세부 정보를 본다.
4. 이메일 등으로 게시자에게 연락한다.
5. 사기성과 오해의 소지가 있는 게시물을 신고한다.

비기능적 요구사항
- 확장성: 단일 도시 최대 1000만명의 사용자만 수용
- 높은 가용성: 99.9% 가동 시간
- 높은 성능: 조회자가 게시물 작성 후 몇 초 내에 볼 수 있어야 함. 검색과 게시물 조회의 P99가 1초
- 보안: 로그인 필요

## 7.2 API

면접에서는 OpenAPI 형식이나 GraphQL 스키마와 같은 정식 API 명세를 작성할 시간이 없으므로 시간 관계상 대략적인 스케치를 사용하겠다고 할 수 있다.

**CRUD 게시물**

- GET과 DELETE /post/{id}
- GET /post?search={search_string}
- POST와 PUT /post
- POST /contact
- POST /report
- DELETE /old_posts

**사용자 관리**
- POST /signup
- POST /login
- DELETE /user

**기타**

- GET /health

다양한 필터가 있으며 단순화를 위해 고정된 필터 세트를 가정한다. 이는 프론트/백엔드 모두에서 구현할 수 있다.

- 동네 정보: enum
- 최소 가격
- 최대 가격
- 물품 상태: enum. NEW, EXCELLENT, GOOD, ACCEPTABLE

## 7.3 SQL 데이터베이스 스키마

- User: id, first_name, last_name, signup_ts
- Post: id, created_at, poster_id, location_id, title, description, price, condition, country_code, state, city, street_number, street_name, phone_number, email
  - 이 테이블은 비정규화 되어있어 게시물의 모든 세부 정보를 가져오기 위해 JOIN 쿼리가 필요하지 않다.
- Images: id, ts, post_id, image_address
- Report: id, ts, post_id, user_id, abuse_type, message
- 이미지 저: 객체 스토리지에 이미지를 저장할 수 있다. AWS S3, Azure Blob storage
- image_address: 객체 스토리지에서 이미지를 검색하는데 사용되는 식별자

## 7.4 초기 고수준 아키텍처

모든 설계에서 로깅 서비스도 포함한다. 하지만 보통 대부분의 클라우드 벤더는 설정이 쉬운 로깅, 모니터링, 알림 도구를 제공하므로 이를 사용한다.

## 7.5 모놀리스 아키텍처

## 7.6 SQL 데이터베이스와 객체 스토리지 사용

## 7.7 마이그레이션은 번거롭다

SQL에 이미지 파일을 저장하는 것의 또 다른 단점은 향후 이를 객체 스토리지에 저장하게 마이그레이션해야 한다는 점이며 이는 까다롭고 힘든 작업이다.

## 7.8 게시물 작성과 읽기

1. 클라이언트는 이미지를 제외한 게시물을 백엔드에 POST 요청을 한다. 백엔드는 SQL 데이터베이스에 쓰고 게시물 ID를 클라이언트에 반환한다.
2. 클라이언트는 이미지 파일을 한번에 하나씩 객체 스토리지에 업로드하거나 스레드를 분기해 병렬 업로드 요청을 할 수 있다.

이 접근법에서 백엔드는 이미지가 객체 스토리지에 성공적으로 업로드되었는지 알 수 없다. 이를 알기 위해서는 백엔드 자체에서 이미지를 업로드해야 한다. 

## 7.9 기능적 분할

확장의 첫 단계는 도시와 같은 지리상 지역별로 기능적 분할을 사용하는 것이다. 예를 들어 지리적 위치에서 시작되는 DNS 쿼리의 위치를 기반으로 트래픽을 서비스하는 것이다.

애플리케이션을 여러 데이터 센터에 배포하고 각 사용자를 해당 도시를 서비스하는 데이터 센터로 라우팅하면 이는 보통 가장 가까운 데이터 센터가 되며 각 데이터 센터의 SQL 클러스터는 서비스하는 도시의 데이터만 포함된다. 

크레이그리스트는 각 도시에 서브 도메인을 할당해 이러한 지리적 분할을 수행한다. 브라우저에 craiglist.org를 입력하면 다음 단계가 수행된다.

1. 인터넷 서비스 제공업체가 craiglist.org DNS 조회를 수행하고 IP 주소를 반환한다. 
2. 브라우저가 craiglist.org의 IP 주소로 요청을 보낸다. 서버는 이 IP 주소를 기반으로 사용자의 위치를 파악하고 우리 위치에 해당하는 서브 도메인이 포함된 3xx 응답을 반환한다. 이 반환된 주소는 브라우저와 사용자의 OS, ISP같은 중간 경로의 다른 매개체에 캐시될 수 있다.
3. 이 서브도메인의 IP 주소를 얻기 위해 또 다른 DNS 조회가 필요하다.
4. 브라우저가 서브도메인의 IP 주소로 요청을 보낸다. 서버는 해당 서브도메인의 웹페이지와 데이터를 반환한다.

## 7.10 캐싱

레디스를 사용해 인기 게시물을 LRU 캐시에 저장할 수 있다. 키는 게시물 ID가 될 수 있고 값은 게시물의 전체 HTML 페이지가 된다. 

## 7.11 CDN

## 7.12 SQL 클러스터로 읽기 확장

읽기 작업 확장이 필요하다면 3장에서 설명한 접근 방식을 따를 수 있으며 그 중 하나가 SQL 복제이다.

## 7.13 쓰기 처리량 확장

**카프카와 같은 메시지 브로커 사용**

쓰기 트래픽 급증을 처리하기 위해 SQL 서비스 앞에 카프카를 배치할 수 있다. 게시자가 새 게시물을 제출하거나 기존 게시물을 업데이트할 때 게시글 토픽에 메시지를 발행한다. 그리고 소비하는 서비스가 이를 지속적으로 소비하여 SQL에 데이터를 쓴다. 

더 높은 쓰기 처리량이 필요하다면 카산드라나 HDFS가 있는 카프카와 같은 NoSQL 데이터베이스를 사용할 수 있다.

## 7.14 이메일 서비스

## 7.15 검색

## 7.16 오래된 게시물 제거

크레이그리스트 게시물은 일정 일수가 지나면 만료돼 더 이상 접근할 수 없게 된다. 이는 크론 작업이나 에어플로우를 사용해 DELETE /old_posts 엔드포인트를 매일 호출하는 방식으로 구현할 수 있다.

이 작업은 간단하고 중요도가 낮기 때문에 크론 작업으로 충분할 수 있으며 에어플로우를 사용하는건 복잡성이 생길 수 있다.

비용이 문제이고 오래된 데이터에 대한 접근이 빈번하지 않다면 삭제의 대안으로 압축 후 테이프와 같은 저비용 아카이브 하드웨어나 AWS 글래시어(Glacier)나 애저 아카이브 스토리지(Azure Archive Storage)같은 곳에 저장하는 방법을 고려할 수 있다.

## 7.17 모니터링과 알림

## 7.18 아키텍처 논의 내용 요약

## 7.19 기타 논의 가능한 주제

### 7.19.1 게시물 신고

### 7.19.2 점진적 기능 저하

### 7.19.3 복잡성

**종속성 최소화**

**클라우드 서비스 사용**

**전체 웹페이지를 HTML 문서로 저장**

게시물의 웹페이지를 데이터베이스나 CDN에 단일 HTML문서로 저장할 수 있다. 이는 키가 게시물의 ID이고 값이 HTML문서인 간단한 키-값 쌍일 수 있다. 이 해결책은 모든 데이터베이스 항목에 중복된 HTML이 포함되므로 일부 저장공간을 트레이드오프한다.

**관찰 가능성**

### 7.19.4 품목 카테고리/태그

### 7.19.5 분석과 추천

### 7.19.6 A/B 테스팅

### 7.19.7 구독과 저장된 검색

### 7.19.8 검색 서비스 중복 요청 허용

일래스틱서치는 빈번한 검색 요청을 캐싱하므로 같은 검색어로 빈번한 요청을 해도 많은 리소스를 낭비하지 않는다.

### 7.19.9 검색 서비스에 중복 요청 피하기

### 7.19.10 속도 제한

서비스 요청은 모두 속도 제한기를 거치도록 설계해야 한다.

### 7.19.11 대량의 게시물

### 7.19.12 지역 규정
